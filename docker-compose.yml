services:
  rabbitmq:
    image: rabbitmq:4-management          # 4.1 with the Management UI
    container_name: rabbitmq
    ports:
      - "5672:5672"                       # AMQP
      - "15672:15672"                     # Management UI
      - "15692:15692"                     # Prometheus metrics
    environment:
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: >-
        -rabbitmq_prometheus.listener.tcp 0.0.0.0 15692
        -rabbit frame_max 1048576
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq   # persist queues/users
    networks:
      - default
  
  server:
    image: server:latest
    build:
      context: ./server
      args:
        USERNAME: ${USERNAME}
        UID: ${UID}
        GID: ${GID}
    volumes:
      - ${WORKSPACE}/server:/app
      - ${X11SOCKET}:${X11SOCKET}
      - ${XAUTHORITY}:${XAUTHORITY}
    environment:
      - RABBITMQ_URL=amqp://rabbitmq
      - VIDEO_FRAMES_EXCHANGE=video_frames_exchange
      - IMU_DATA_EXCHANGE=imu_data_exchange
      - PROCESSED_FRAMES_EXCHANGE=processed_frames_exchange
      - ANALYSIS_MODE_EXCHANGE=analysis_mode_exchange
      - RESTART_EXCHANGE=restart_exchange
      - BIND_HOST=0.0.0.0
      - API_PORT=5001
      - PYTHONUNBUFFERED=1
    ports:
      - "5001:5001"  # API/WebSocket
    depends_on:
      - rabbitmq
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health/video"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frame_processor:
    build:
      context: .
      dockerfile: ./frame_processor/Dockerfile
    image: frame_processor:latest
    runtime: nvidia
    profiles: ["frame_processor"]
    network_mode: host
    environment:
      # ========== WebSocket Video Configuration ==========
      - VIDEO_STREAM_URL=ws://127.0.0.1:5001/ws/video/consume
      - VIDEO_STREAM_TYPE=websocket
      # ========== Core RabbitMQ Configuration ==========
      - RABBITMQ_URL=amqp://127.0.0.1:5672
      - PROCESSED_FRAMES_EXCHANGE=processed_frames_exchange
      - API_RESULTS_EXCHANGE=api_results_exchange
      - FRAME_PROCESSOR_SKIP=${FRAME_PROCESSOR_SKIP:-1}  # Process every Nth frame (1=no skip)
      
      # ========== Configuration ==========
      - CONFIG_PROFILE=${CONFIG_PROFILE:-balanced}  # performance, balanced, quality
      
      # Performance settings (auto-configured by profile)
      - TARGET_FPS=${TARGET_FPS:-15}
      - PROCESSING_RESOLUTION=${PROCESSING_RESOLUTION:-720}
      - MODEL_NAME=${MODEL_NAME:-sam2_tiny}  # Options: sam2_tiny, sam2_small, sam2_base_plus, sam2_large, fastsam_x
      
      # Video tracker configuration - optimized for performance
      - VIDEO_TRACKER_TYPE=${VIDEO_TRACKER_TYPE:-sam2_realtime}  # Use SAM2 realtime tracker
      - REPROMPT_INTERVAL=${REPROMPT_INTERVAL:-5}  # Re-detect objects every 5 frames
      - MAX_TRACKS=${MAX_TRACKS:-5}  # Limit to 5 objects for performance
      - SAM_VIDEO_MIN_AREA=${SAM_VIDEO_MIN_AREA:-1000}  # Min area threshold to filter small objects
      
      # ========== System Configuration ==========
      - DEVICE=cuda
      - NVIDIA_VISIBLE_DEVICES=all
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - RERUN_ENABLED=${RERUN_ENABLED:-true}
      - RERUN_CONNECT_URL=${RERUN_CONNECT_URL:-rerun+http://127.0.0.1:9876/proxy}
      - USE_VISUALIZATION_OUTPUT=${USE_VISUALIZATION_OUTPUT:-true}
      
      # ========== API Configuration ==========
      - USE_SERPAPI=${USE_SERPAPI:-false}
      - USE_GCS=${USE_GCS:-true}
      - USE_PERPLEXITY=${USE_PERPLEXITY:-false}
      - SERPAPI_KEY=${SERPAPI_KEY}
      - PERPLEXITY_KEY=${PERPLEXITY_KEY}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/worldsystem-23f7306a1a75.json
      - GCS_BUCKET_NAME=${GCS_BUCKET_NAME:-worldsystem-frame-processor}
      
      # ========== Advanced Settings (Usually Don't Need to Change) ==========
      # Video Processing
      - GRID_PROMPT_DENSITY=${GRID_PROMPT_DENSITY:-16}
      - REPROMPT_INTERVAL=${REPROMPT_INTERVAL:-60}
      - MIN_OBJECT_AREA=${MIN_OBJECT_AREA:-1000}
      - VIDEO_BUFFER_SIZE=${VIDEO_BUFFER_SIZE:-30}
      
      # SAM2 Video-Specific Thresholds (for better video quality)
      - SAM_VIDEO_PRED_IOU_THRESH=${SAM_VIDEO_PRED_IOU_THRESH:-0.7}  # Lower than image mode (0.86)
      - SAM_VIDEO_STABILITY_SCORE_THRESH=${SAM_VIDEO_STABILITY_SCORE_THRESH:-0.85}  # Lower than image mode (0.92)
      - SAM_VIDEO_MIN_AREA=${SAM_VIDEO_MIN_AREA:-500}  # Minimum mask area in pixels
      
      # Stream Management
      - STREAM_STALE_TIMEOUT_SECONDS=${STREAM_STALE_TIMEOUT_SECONDS:-30}
      - STREAM_CLEANUP_TIMEOUT_SECONDS=${STREAM_CLEANUP_TIMEOUT_SECONDS:-120}
      
      # Google Lens Batch Processing
      - LENS_BATCH_SIZE=${LENS_BATCH_SIZE:-10}
      - LENS_BATCH_WAIT_MS=${LENS_BATCH_WAIT_MS:-500}
      - PROCESS_AFTER_SECONDS=${PROCESS_AFTER_SECONDS:-1.5}
      
      # GPU Memory Management
      - ENABLE_DYNAMIC_MODEL_SWITCHING=${ENABLE_DYNAMIC_MODEL_SWITCHING:-true}
      - MODEL_SWITCH_THRESHOLD_MB=${MODEL_SWITCH_THRESHOLD_MB:-3000}
      
      # Enhancement Configuration
      - ENHANCEMENT_ENABLED=${ENHANCEMENT_ENABLED:-false}
      
      # Rich Terminal Display
      - ENABLE_RICH_TERMINAL=${ENABLE_RICH_TERMINAL:-false}
      
    volumes:
      - ${WORKSPACE}/frame_processor/models:/app/models:ro
      - ${WORKSPACE}/frame_processor/credentials/worldsystem-23f7306a1a75.json:/app/worldsystem-23f7306a1a75.json:ro
      - ${WORKSPACE}/frame_processor/logs:/app/logs
      - ${WORKSPACE}/common:/app/common:ro
      - ${X11SOCKET}:${X11SOCKET}
      - ${XAUTHORITY}:${XAUTHORITY}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    depends_on:
      - rabbitmq
      - server
    healthcheck:
      test: ["CMD", "python3", "-c", "import requests; requests.get('http://127.0.0.1:5001/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # TTY configuration for rich terminal display
    # Set ENABLE_RICH_TERMINAL=true and run with -t flag for interactive terminal
    tty: ${ENABLE_RICH_TERMINAL:-false}
    stdin_open: ${ENABLE_RICH_TERMINAL:-false}

  slam3r:
    image: slam3r:latest
    profiles: ["slam3r"]
    privileged: true
    build:
      context: ./slam3r
      args:
        USERNAME: ${USERNAME}
        UID: ${UID}
        GID: ${GID}
    container_name: slam3r
    runtime: nvidia
    pid: host
    cap_add:
     - SYS_PTRACE

    # Mount source and checkpoints
    volumes:
      - ${WORKSPACE}/slam3r/SLAM3R_engine/slam3r_processor.py:/app/SLAM3R_engine/slam3r_processor.py
      - ${WORKSPACE}/slam3r/SLAM3R_engine/streaming_slam3r.py:/app/SLAM3R_engine/streaming_slam3r.py
      - ${WORKSPACE}/slam3r/SLAM3R_engine/configs:/app/SLAM3R_engine/configs
      - ${WORKSPACE}/slam3r/SLAM3R_engine/shared_memory.py:/app/SLAM3R_engine/shared_memory.py
      - ${WORKSPACE}/slam3r/checkpoints:/checkpoints_mount
      - /dev/shm:/dev/shm  # Shared memory for IPC with mesh_service
      - ${X11SOCKET}:${X11SOCKET}
      - ${XAUTHORITY}:${XAUTHORITY}
      - ./slam3r/debug_output:/debug_output  # Mount local directory for debug saves

    # ---------- key change: share the host network namespace ----------
    network_mode: host

    # ========== MEMORY AND RESOURCE MANAGEMENT ==========
    # Shared memory for PyTorch (important for multi-process data loading)
    shm_size: '4gb'  # Reduced from 8gb since GPU is shared
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Health check to detect and recover from OOM
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; assert torch.cuda.is_available(); assert torch.cuda.memory_allocated() < 20e9"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # Auto-restart on crashes (including OOM)
    restart: unless-stopped

    # ‼️ host‑network means container DNS can't resolve other service names; connect via 127.0.0.1 instead
    environment:
      # ========== EXISTING CONFIGURATION ==========
      # RabbitMQ now reached on the host‑published port
      - RABBITMQ_URL=amqp://127.0.0.1:5672

      # Input exchanges
      - VIDEO_FRAMES_EXCHANGE=video_frames_exchange
      - TRAJECTORY_DATA_EXCHANGE=trajectory_data_exchange
      - PLY_FANOUT_EXCHANGE=ply_fanout_exchange
      - RESTART_EXCHANGE=restart_exchange

      # Output exchanges
      - SLAM3R_POSE_EXCHANGE=${SLAM3R_POSE_EXCHANGE:-slam3r_pose_exchange}
      - SLAM3R_POINTCLOUD_EXCHANGE=${SLAM3R_POINTCLOUD_EXCHANGE:-slam3r_pointcloud_exchange}
      - SLAM3R_RECONSTRUCTION_VIS_EXCHANGE=${SLAM3R_RECONSTRUCTION_VIS_EXCHANGE:-slam3r_reconstruction_vis_exchange}
      - SLAM3R_KEYFRAME_EXCHANGE=${SLAM3R_KEYFRAME_EXCHANGE:-slam3r_keyframe_exchange}
      - SLAM3R_OUTPUT_TO_RABBITMQ=${SLAM3R_OUTPUT_TO_RABBITMQ:-false}
      
      # WebSocket video stream URL
      - VIDEO_STREAM_URL=ws://127.0.0.1:5001/ws/video/consume

      # Paths & checkpoints
      - SLAM3R_CHECKPOINTS_DIR=/checkpoints_mount
      - SLAM3R_CONFIG_FILE=/app/SLAM3R_engine/configs/wild.yaml
      - CAMERA_INTRINSICS_FILE=/app/SLAM3R_engine/configs/camera_intrinsics.yaml

      # Rerun viewer (host‑local)
      - RERUN_VIEWER_ADDRESS=127.0.0.1:9876
      # For SSH reverse tunnel: use localhost
      # For direct connection: use your MacBook's IP address
      - RERUN_CONNECT_URL=${RERUN_CONNECT_URL:-rerun+http://127.0.0.1:9876/proxy}
      - RERUN_ENABLED=${RERUN_ENABLED:-true}

      # GPU / display
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_PATH=${CUDA_PATH}
      - LIBGL_ALWAYS_INDIRECT=${LIBGL_ALWAYS_INDIRECT}
      - DISPLAY=${DISPLAY}

      # ========== MEMORY MANAGEMENT (CRITICAL FOR 3090) ==========
      # PyTorch memory allocation strategy - VERY IMPORTANT
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:256,garbage_collection_threshold:0.7
      
      # Enable CUDA memory debugging in case of issues
      - CUDA_LAUNCH_BLOCKING=${CUDA_LAUNCH_BLOCKING:-0}
      
      # Frame history and tensor cache limits (conservative for shared GPU)
      - SLAM3R_MAX_HISTORY_SIZE=300  # Reduced from 500
      - SLAM3R_MAX_TENSOR_CACHE=50   # Reduced from 100
      - SLAM3R_MAX_POINTCLOUD_SIZE=750000  # Reduced from 1M
      
      # Force garbage collection interval
      - SLAM3R_GC_INTERVAL=30  # seconds

      # ========== VISUALIZATION OPTIMIZATION ==========
      # Batch processing for Rerun to reduce overhead
      - SLAM3R_RERUN_BATCH_SIZE=15  # Increased for better batching
      - SLAM3R_RERUN_VOXEL_SIZE=0.008  # Slightly larger for performance
      - SLAM3R_RERUN_KEYFRAME_VOXEL_SIZE=0.005  # Better quality for keyframes
      
      # Limit visualization updates
      - SLAM3R_VIZ_UPDATE_INTERVAL=5  # Only update viz every N frames

      # ========== ADAPTIVE TRACKING FOR CORRIDORS ==========
      # Scene detection and adaptive keyframing
      - SLAM3R_SCENE_DETECTION_ENABLED=true
      - SLAM3R_CORRIDOR_DETECTION_WINDOW=20
      - SLAM3R_CORRIDOR_EIGENVALUE_RATIO=5.0
      
      # Keyframe adaptation parameters
      - KEYFRAME_STRIDE=-1  # Auto-adaptive
      - SLAM3R_KEYFRAME_ADAPT_MIN=1
      - SLAM3R_KEYFRAME_ADAPT_MAX=15  # Reduced max for better tracking
      - SLAM3R_KEYFRAME_ADAPT_STRIDE_STEP=1
      
      # Buffer strategies
      - SLAM3R_BUFFER_STRATEGY=${SLAM3R_BUFFER_STRATEGY:-reservoir}  # Default
      - SLAM3R_BUFFER_SIZE=80  # Reduced for memory
      - SLAM3R_UPDATE_BUFFER_INTV=1
      
      # Corridor-specific thresholds
      - SLAM3R_CORRIDOR_POSITION_THRESHOLD=0.4  # meters
      - SLAM3R_CORRIDOR_ROTATION_THRESHOLD=12   # degrees
      - SLAM3R_ROOM_POSITION_THRESHOLD=0.8      # meters
      - SLAM3R_ROOM_ROTATION_THRESHOLD=25       # degrees

      # ========== SLAM3R ALGORITHM PARAMETERS ==========
      # Confidence thresholds (tuned for quality vs memory)
      - SLAM3R_CONF_THRES_I2P=1.8  # Slightly higher to reduce points
      - SLAM3R_CONF_THRES_L2W=14.0  # Higher threshold for cleaner results
      
      # Window and scene parameters
      - SLAM3R_INITIAL_WINSIZE=5
      - SLAM3R_WIN_R=4  # Slightly reduced
      - SLAM3R_NUM_SCENE_FRAME=8  # Reduced from 10
      - SLAM3R_MAX_NUM_REGISTER=8  # Reduced from 10

      # ========== PERFORMANCE TUNING ==========
      # Thread limits to prevent CPU oversubscription
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - NUMEXPR_NUM_THREADS=4
      
      # Python settings
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app:$PYTHONPATH
      
      # Logging level
      - SLAM3R_LOG_LEVEL=${SLAM3R_LOG_LEVEL:-INFO}

      # ========== INITIALIZATION QUALITY ==========
      - INITIALIZATION_QUALITY_MIN_AVG_CONFIDENCE=1.2
      - INITIALIZATION_QUALITY_MIN_TOTAL_VALID_POINTS=150

      # ========== VIDEO SEGMENT HANDLING ==========
      # Save point clouds and trajectories when transitioning between segments
      - SLAM3R_SAVE_SEGMENT_POINTCLOUDS=${SLAM3R_SAVE_SEGMENT_POINTCLOUDS:-false}
      - SLAM3R_SEGMENT_OUTPUT_DIR=${SLAM3R_SEGMENT_OUTPUT_DIR:-/tmp/slam3r_segments}

      # ========== POINT CLOUD DEBUGGING ==========
      # Save point clouds to PLY files for verification
      - SLAM3R_SAVE_PCD=${SLAM3R_SAVE_PCD:-true}
      - SLAM3R_PCD_OUTPUT_DIR=${SLAM3R_PCD_OUTPUT_DIR:-/debug_output/pcd}

      # ========== MISC ==========
      - HOME=${HOME}
      - TZ=${TZ:-UTC}

    depends_on:
      - rabbitmq
    
    # Resource usage logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  mesh_service:
    image: mesh_service:latest
    profiles: ["mesh_service", "slam3r"]
    build:
      context: ./mesh_service
    container_name: mesh_service
    network_mode: host

    volumes:
      - /dev/shm:/dev/shm  # Shared memory for SLAM3R keyframes
      - ./mesh_service/debug_output:/debug_output

    shm_size: '4gb'

    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    restart: unless-stopped

    environment:
      # RabbitMQ Configuration
      - RABBITMQ_URL=amqp://127.0.0.1:5672

      # Rerun Configuration
      - RERUN_HOST=127.0.0.1
      - RERUN_PORT=9876
      - RERUN_CONNECT=true

      # Point Cloud Configuration
      - VOXEL_SIZE=${VOXEL_SIZE:-0.02}  # 2cm voxels
      - MAX_POINTS=${MAX_POINTS:-500000}  # Display cap
      - MAX_RAW_POINTS=${MAX_RAW_POINTS:-1000000}  # Auto-downsample threshold
      - LOG_INTERVAL_MS=${LOG_INTERVAL_MS:-500}  # Rerun update rate

      # Shared Memory
      - MESH_SERVICE_UNLINK_SHM=${MESH_SERVICE_UNLINK_SHM:-true}

      # Video Configuration
      - ENABLE_VIDEO=${ENABLE_VIDEO:-true}
      - VIDEO_LOG_INTERVAL_MS=${VIDEO_LOG_INTERVAL_MS:-100}  # 10fps

      # System Configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ENABLE_METRICS=${ENABLE_METRICS:-true}
      - PYTHONUNBUFFERED=1

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    depends_on:
      - rabbitmq

  simulator:
    build: ./simulation  # or point to a Dockerfile that includes your simulation script
    profiles: ["simulator"]
    image: simulator:latest
    network_mode: host
    restart: "no"  # Don't restart when simulation completes
    environment:
      - PYTHONUNBUFFERED=1  # Ensures Python output is sent straight to the terminal
      - SERVER_WS_URL=ws://127.0.0.1:5001/ws/video  # WebSocket URL for H.264 streaming
      - SIMULATION_MODE=${SIMULATION_MODE:-video}  # Set to 'video' or 'segments'

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - "9090:9090"
    extra_hosts:
    - "host.docker.internal:host-gateway"
    depends_on:
      - cadvisor
    networks:
      - default

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - default

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - default
    cpus: '0.2'

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    environment:
      COLLECTOR_OTLP_ENABLED: "true"       # Enable OTLP ingestion
      COLLECTOR_OTLP_HTTP_HOST_PORT: ":4318"
    ports:
      - "16686:16686"    # Jaeger UI
      - "6831/udp"       # Legacy agent port
      - "6832/udp"
      - "14268:14268"
      - "4318:4318"      # OTLP endpoint
    networks:
      - default

  nvidia-dcgm-exporter:
    # use NVIDIA's canonical registry & newest tag
    image: nvcr.io/nvidia/k8s/dcgm-exporter:4.2.3-4.1.1-ubuntu22.04
    container_name: nvidia-dcgm-exporter
    runtime: nvidia

    # full set of GPU‑profiling metrics needs SYS_ADMIN
    cap_add:
      - SYS_ADMIN

    environment:
      - NVIDIA_VISIBLE_DEVICES=all        # all GPUs
    ports:
      - "9400:9400"

    networks:
      - default

  storage:
    build:
      context: .
      dockerfile: ./storage/Dockerfile
    image: storage:latest
    profiles: ["storage"]
    container_name: worldsystem-storage
    network_mode: host
    environment:
      # ========== WebSocket Video Configuration ==========
      - VIDEO_STREAM_URL=ws://127.0.0.1:5001/ws/video/consume
      - VIDEO_STREAM_TYPE=websocket
      # ========== RabbitMQ Configuration ==========
      - RABBITMQ_URL=amqp://127.0.0.1:5672
      - FRAME_PROCESSOR_SKIP=1  # Record every frame
      
      # ========== Storage Configuration ==========
      - STORAGE_PATH=/app/recordings
      - VIDEO_CHUNK_DURATION_SECONDS=${VIDEO_CHUNK_DURATION_SECONDS:-60}  # 1 minute chunks by default
      - VIDEO_IDLE_TIMEOUT_SECONDS=${VIDEO_IDLE_TIMEOUT_SECONDS:-10.0}  # Save partial chunk after 10s of no frames
      - MIN_CHUNK_FRAMES=${MIN_CHUNK_FRAMES:-30}  # Minimum frames to save a partial chunk
      - USE_H264_CODEC=${USE_H264_CODEC:-false}  # Use H.264 codec instead of MJPEG
      
      # ========== System Configuration ==========
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - METRICS_PORT=8005
      - PYTHONUNBUFFERED=1
      
    volumes:
      - ${WORKSPACE}/storage:/app/storage:ro
      - ${WORKSPACE}/common:/app/common:ro
      - ${WORKSPACE}/recordings:/app/recordings
      - ${WORKSPACE}/data:/data  # Legacy compatibility
      
    depends_on:
      - rabbitmq
      
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://127.0.0.1:5001/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  visualization:
    build:
      context: .
      dockerfile: ./visualization/Dockerfile
    image: visualization:latest
    profiles: ["visualization"]
    container_name: worldsystem-visualization
    network_mode: host
    environment:
      # ========== RabbitMQ Configuration ==========
      - RABBITMQ_URL=amqp://127.0.0.1:5672
      - FRAME_PROCESSOR_OUTPUTS_EXCHANGE=processed_frames_exchange
      
      # ========== Rerun Configuration ==========
      - RERUN_PORT=${RERUN_PORT:-9876}
      - RERUN_ENABLED=${RERUN_ENABLED:-true}
      
      # ========== System Configuration ==========
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      
    volumes:
      - ${WORKSPACE}/visualization:/app/visualization:ro
      - ${WORKSPACE}/common:/app/common:ro
      - ${WORKSPACE}/frame_processor/outputs:/app/outputs:ro
      
    depends_on:
      - rabbitmq
      
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  default:
    driver: bridge

volumes:
  grafana-data:
  rabbitmq-data:
