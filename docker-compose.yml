services:
  rabbitmq:
    image: rabbitmq:4-management          # 4.1 with the Management UI
    container_name: rabbitmq
    ports:
      - "5672:5672"                       # AMQP
      - "15672:15672"                     # Management UI
      - "15692:15692"                     # Prometheus metrics
    environment:
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: >-
        -rabbitmq_prometheus.listener.tcp 0.0.0.0 15692
        -rabbit frame_max 1048576
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq   # persist queues/users
    networks:
      - default
  
  nginx:
    build: ./nginx
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - server
  
  server:
    image: server:latest
    build:
      context: ./server
      args:
        USERNAME: ${USERNAME}
        UID: ${UID}
        GID: ${GID}
    volumes:
      - ${WORKSPACE}/server:/app
      - ${X11SOCKET}:${X11SOCKET}
      - ${XAUTHORITY}:${XAUTHORITY}
    environment:
      - RABBITMQ_URL=amqp://rabbitmq
      - VIDEO_FRAMES_EXCHANGE=video_frames_exchange
      - IMU_DATA_EXCHANGE=imu_data_exchange
      - PROCESSED_FRAMES_EXCHANGE=processed_frames_exchange
      - ANALYSIS_MODE_EXCHANGE=analysis_mode_exchange
      - RESTART_EXCHANGE=restart_exchange
      - BIND_HOST=0.0.0.0
      - API_PORT=5001
      - PYTHONUNBUFFERED=1
    ports:
      - "5001:5001"  # API/WebSocket
    depends_on:
      - rabbitmq
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health/video"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frame_processor:
    build:
      context: .
      dockerfile: ./frame_processor/Dockerfile
    image: frame_processor:latest
    runtime: nvidia
    profiles: ["frame_processor"]
    network_mode: host
    environment:
      # ========== WebSocket Video Configuration ==========
      - VIDEO_STREAM_URL=ws://127.0.0.1:5001/ws/video/consume
      - VIDEO_STREAM_TYPE=websocket
      # ========== Core RabbitMQ Configuration ==========
      - RABBITMQ_URL=amqp://127.0.0.1:5672
      - PROCESSED_FRAMES_EXCHANGE=processed_frames_exchange
      - API_RESULTS_EXCHANGE=api_results_exchange
      - FRAME_PROCESSOR_SKIP=1  # Process every frame
      
      # ========== Configuration ==========
      - CONFIG_PROFILE=${CONFIG_PROFILE:-balanced}  # performance, balanced, quality
      
      # Performance settings (auto-configured by profile)
      - TARGET_FPS=${TARGET_FPS:-15}
      - PROCESSING_RESOLUTION=${PROCESSING_RESOLUTION:-720}
      - MODEL_NAME=${MODEL_NAME:-sam2_base_plus}  # Options: sam2_tiny, sam2_small, sam2_base_plus, sam2_large, fastsam_x
      
      # ========== System Configuration ==========
      - DEVICE=cuda
      - NVIDIA_VISIBLE_DEVICES=all
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - RERUN_ENABLED=${RERUN_ENABLED:-true}
      - RERUN_CONNECT_URL=${RERUN_CONNECT_URL:-rerun+http://127.0.0.1:9876/proxy}
      
      # ========== API Configuration ==========
      - USE_SERPAPI=${USE_SERPAPI:-false}
      - USE_GCS=${USE_GCS:-true}
      - USE_PERPLEXITY=${USE_PERPLEXITY:-false}
      - SERPAPI_KEY=${SERPAPI_KEY}
      - PERPLEXITY_KEY=${PERPLEXITY_KEY}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/worldsystem-23f7306a1a75.json
      - GCS_BUCKET_NAME=${GCS_BUCKET_NAME:-worldsystem-frame-processor}
      
      # ========== Advanced Settings (Usually Don't Need to Change) ==========
      # Video Processing
      - GRID_PROMPT_DENSITY=${GRID_PROMPT_DENSITY:-16}
      - REPROMPT_INTERVAL=${REPROMPT_INTERVAL:-60}
      - MIN_OBJECT_AREA=${MIN_OBJECT_AREA:-1000}
      - VIDEO_BUFFER_SIZE=${VIDEO_BUFFER_SIZE:-30}
      
      # SAM2 Video-Specific Thresholds (for better video quality)
      - SAM_VIDEO_PRED_IOU_THRESH=${SAM_VIDEO_PRED_IOU_THRESH:-0.7}  # Lower than image mode (0.86)
      - SAM_VIDEO_STABILITY_SCORE_THRESH=${SAM_VIDEO_STABILITY_SCORE_THRESH:-0.85}  # Lower than image mode (0.92)
      - SAM_VIDEO_MIN_AREA=${SAM_VIDEO_MIN_AREA:-500}  # Minimum mask area in pixels
      
      # Stream Management
      - STREAM_STALE_TIMEOUT_SECONDS=${STREAM_STALE_TIMEOUT_SECONDS:-30}
      - STREAM_CLEANUP_TIMEOUT_SECONDS=${STREAM_CLEANUP_TIMEOUT_SECONDS:-120}
      
      # Google Lens Batch Processing
      - LENS_BATCH_SIZE=${LENS_BATCH_SIZE:-10}
      - LENS_BATCH_WAIT_MS=${LENS_BATCH_WAIT_MS:-500}
      - PROCESS_AFTER_SECONDS=${PROCESS_AFTER_SECONDS:-1.5}
      
      # GPU Memory Management
      - ENABLE_DYNAMIC_MODEL_SWITCHING=${ENABLE_DYNAMIC_MODEL_SWITCHING:-true}
      - MODEL_SWITCH_THRESHOLD_MB=${MODEL_SWITCH_THRESHOLD_MB:-3000}
      
      # Enhancement Configuration
      - ENHANCEMENT_ENABLED=${ENHANCEMENT_ENABLED:-false}
      
      # Rich Terminal Display
      - ENABLE_RICH_TERMINAL=${ENABLE_RICH_TERMINAL:-false}
      
    volumes:
      - ${WORKSPACE}/frame_processor/models:/app/models:ro
      - ${WORKSPACE}/frame_processor/credentials/worldsystem-23f7306a1a75.json:/app/worldsystem-23f7306a1a75.json:ro
      - ${WORKSPACE}/frame_processor/logs:/app/logs
      - ${WORKSPACE}/common:/app/common:ro
      - ${X11SOCKET}:${X11SOCKET}
      - ${XAUTHORITY}:${XAUTHORITY}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    depends_on:
      - rabbitmq
      - server
    healthcheck:
      test: ["CMD", "python3", "-c", "import requests; requests.get('http://127.0.0.1:5001/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # TTY configuration for rich terminal display
    # Set ENABLE_RICH_TERMINAL=true and run with -t flag for interactive terminal
    tty: ${ENABLE_RICH_TERMINAL:-false}
    stdin_open: ${ENABLE_RICH_TERMINAL:-false}

  slam3r:
    image: slam3r:latest
    profiles: ["slam3r"]
    privileged: true
    build:
      context: ./slam3r
      args:
        USERNAME: ${USERNAME}
        UID: ${UID}
        GID: ${GID}
    container_name: slam3r
    runtime: nvidia
    pid: host
    cap_add:
     - SYS_PTRACE

    # Mount source and checkpoints
    volumes:
      - ${WORKSPACE}/slam3r/SLAM3R_engine/slam3r_processor.py:/app/SLAM3R_engine/slam3r_processor.py
      - ${WORKSPACE}/slam3r/SLAM3R_engine/streaming_slam3r.py:/app/SLAM3R_engine/streaming_slam3r.py
      - ${WORKSPACE}/slam3r/SLAM3R_engine/configs:/app/SLAM3R_engine/configs
      - ${WORKSPACE}/slam3r/SLAM3R_engine/shared_memory.py:/app/SLAM3R_engine/shared_memory.py
      - ${WORKSPACE}/slam3r/checkpoints:/checkpoints_mount
      - /dev/shm:/dev/shm  # Shared memory for IPC with mesh_service
      - ${X11SOCKET}:${X11SOCKET}
      - ${XAUTHORITY}:${XAUTHORITY}
      - ./slam3r/debug_output:/debug_output  # Mount local directory for debug saves

    # ---------- key change: share the host network namespace ----------
    network_mode: host

    # ========== MEMORY AND RESOURCE MANAGEMENT ==========
    # Shared memory for PyTorch (important for multi-process data loading)
    shm_size: '4gb'  # Reduced from 8gb since GPU is shared
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Health check to detect and recover from OOM
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; assert torch.cuda.is_available(); assert torch.cuda.memory_allocated() < 20e9"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # Auto-restart on crashes (including OOM)
    restart: unless-stopped

    # ‼️ host‑network means container DNS can't resolve other service names; connect via 127.0.0.1 instead
    environment:
      # ========== EXISTING CONFIGURATION ==========
      # RabbitMQ now reached on the host‑published port
      - RABBITMQ_URL=amqp://127.0.0.1:5672

      # Input exchanges
      - VIDEO_FRAMES_EXCHANGE=video_frames_exchange
      - TRAJECTORY_DATA_EXCHANGE=trajectory_data_exchange
      - PLY_FANOUT_EXCHANGE=ply_fanout_exchange
      - RESTART_EXCHANGE=restart_exchange

      # Output exchanges
      - SLAM3R_POSE_EXCHANGE=${SLAM3R_POSE_EXCHANGE:-slam3r_pose_exchange}
      - SLAM3R_POINTCLOUD_EXCHANGE=${SLAM3R_POINTCLOUD_EXCHANGE:-slam3r_pointcloud_exchange}
      - SLAM3R_RECONSTRUCTION_VIS_EXCHANGE=${SLAM3R_RECONSTRUCTION_VIS_EXCHANGE:-slam3r_reconstruction_vis_exchange}
      - SLAM3R_KEYFRAME_EXCHANGE=${SLAM3R_KEYFRAME_EXCHANGE:-slam3r_keyframe_exchange}
      - SLAM3R_OUTPUT_TO_RABBITMQ=${SLAM3R_OUTPUT_TO_RABBITMQ:-false}

      # Paths & checkpoints
      - SLAM3R_CHECKPOINTS_DIR=/checkpoints_mount
      - SLAM3R_CONFIG_FILE=/app/SLAM3R_engine/configs/wild.yaml
      - CAMERA_INTRINSICS_FILE=/app/SLAM3R_engine/configs/camera_intrinsics.yaml

      # Rerun viewer (host‑local)
      - RERUN_VIEWER_ADDRESS=127.0.0.1:9876
      # For SSH reverse tunnel: use localhost
      # For direct connection: use your MacBook's IP address
      - RERUN_CONNECT_URL=${RERUN_CONNECT_URL:-rerun+http://127.0.0.1:9876/proxy}
      - RERUN_ENABLED=${RERUN_ENABLED:-true}

      # GPU / display
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_PATH=${CUDA_PATH}
      - LIBGL_ALWAYS_INDIRECT=${LIBGL_ALWAYS_INDIRECT}
      - DISPLAY=${DISPLAY}

      # ========== MEMORY MANAGEMENT (CRITICAL FOR 3090) ==========
      # PyTorch memory allocation strategy - VERY IMPORTANT
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:256,garbage_collection_threshold:0.7
      
      # Enable CUDA memory debugging in case of issues
      - CUDA_LAUNCH_BLOCKING=${CUDA_LAUNCH_BLOCKING:-0}
      
      # Frame history and tensor cache limits (conservative for shared GPU)
      - SLAM3R_MAX_HISTORY_SIZE=300  # Reduced from 500
      - SLAM3R_MAX_TENSOR_CACHE=50   # Reduced from 100
      - SLAM3R_MAX_POINTCLOUD_SIZE=750000  # Reduced from 1M
      
      # Force garbage collection interval
      - SLAM3R_GC_INTERVAL=30  # seconds

      # ========== VISUALIZATION OPTIMIZATION ==========
      # Batch processing for Rerun to reduce overhead
      - SLAM3R_RERUN_BATCH_SIZE=15  # Increased for better batching
      - SLAM3R_RERUN_VOXEL_SIZE=0.008  # Slightly larger for performance
      - SLAM3R_RERUN_KEYFRAME_VOXEL_SIZE=0.005  # Better quality for keyframes
      
      # Limit visualization updates
      - SLAM3R_VIZ_UPDATE_INTERVAL=5  # Only update viz every N frames

      # ========== ADAPTIVE TRACKING FOR CORRIDORS ==========
      # Scene detection and adaptive keyframing
      - SLAM3R_SCENE_DETECTION_ENABLED=true
      - SLAM3R_CORRIDOR_DETECTION_WINDOW=20
      - SLAM3R_CORRIDOR_EIGENVALUE_RATIO=5.0
      
      # Keyframe adaptation parameters
      - KEYFRAME_STRIDE=-1  # Auto-adaptive
      - SLAM3R_KEYFRAME_ADAPT_MIN=1
      - SLAM3R_KEYFRAME_ADAPT_MAX=15  # Reduced max for better tracking
      - SLAM3R_KEYFRAME_ADAPT_STRIDE_STEP=1
      
      # Buffer strategies
      - SLAM3R_BUFFER_STRATEGY=${SLAM3R_BUFFER_STRATEGY:-reservoir}  # Default
      - SLAM3R_BUFFER_SIZE=80  # Reduced for memory
      - SLAM3R_UPDATE_BUFFER_INTV=1
      
      # Corridor-specific thresholds
      - SLAM3R_CORRIDOR_POSITION_THRESHOLD=0.4  # meters
      - SLAM3R_CORRIDOR_ROTATION_THRESHOLD=12   # degrees
      - SLAM3R_ROOM_POSITION_THRESHOLD=0.8      # meters
      - SLAM3R_ROOM_ROTATION_THRESHOLD=25       # degrees

      # ========== SLAM3R ALGORITHM PARAMETERS ==========
      # Confidence thresholds (tuned for quality vs memory)
      - SLAM3R_CONF_THRES_I2P=1.8  # Slightly higher to reduce points
      - SLAM3R_CONF_THRES_L2W=14.0  # Higher threshold for cleaner results
      
      # Window and scene parameters
      - SLAM3R_INITIAL_WINSIZE=5
      - SLAM3R_WIN_R=4  # Slightly reduced
      - SLAM3R_NUM_SCENE_FRAME=8  # Reduced from 10
      - SLAM3R_MAX_NUM_REGISTER=8  # Reduced from 10

      # ========== PERFORMANCE TUNING ==========
      # Thread limits to prevent CPU oversubscription
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - NUMEXPR_NUM_THREADS=4
      
      # Python settings
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app:$PYTHONPATH
      
      # Logging level
      - SLAM3R_LOG_LEVEL=${SLAM3R_LOG_LEVEL:-INFO}

      # ========== INITIALIZATION QUALITY ==========
      - INITIALIZATION_QUALITY_MIN_AVG_CONFIDENCE=1.2
      - INITIALIZATION_QUALITY_MIN_TOTAL_VALID_POINTS=150

      # ========== VIDEO SEGMENT HANDLING ==========
      # Save point clouds and trajectories when transitioning between segments
      - SLAM3R_SAVE_SEGMENT_POINTCLOUDS=${SLAM3R_SAVE_SEGMENT_POINTCLOUDS:-false}
      - SLAM3R_SEGMENT_OUTPUT_DIR=${SLAM3R_SEGMENT_OUTPUT_DIR:-/tmp/slam3r_segments}

      # ========== POINT CLOUD DEBUGGING ==========
      # Save point clouds to PLY files for verification
      - SLAM3R_SAVE_PCD=${SLAM3R_SAVE_PCD:-true}
      - SLAM3R_PCD_OUTPUT_DIR=${SLAM3R_PCD_OUTPUT_DIR:-/debug_output/pcd}

      # ========== MISC ==========
      - HOME=${HOME}
      - TZ=${TZ:-UTC}

    depends_on:
      - rabbitmq
    
    # Resource usage logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  mesh_service:
    image: mesh_service:latest
    profiles: ["mesh_service", "slam3r"]  # Run with slam3r profile
    build:
      context: ./mesh_service
      args:
        USERNAME: ${USERNAME}
        UID: ${UID}
        GID: ${GID}
    container_name: mesh_service
    runtime: nvidia
    network_mode: host  # Same as SLAM3R for shared memory access
    
    # Volume mounts
    volumes:
      - /dev/shm:/dev/shm  # Shared memory for zero-copy IPC with SLAM3R
      - ${X11SOCKET}:${X11SOCKET}
      - ${XAUTHORITY}:${XAUTHORITY}
      - ./mesh_service/debug_output:/debug_output  # Mount local directory for debug saves
    
    # Shared memory size for large point clouds
    shm_size: '4gb'
    
    # Resource management
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # Health check for monitoring
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    # Auto-restart on crashes
    restart: unless-stopped
    
    environment:
      # ========== RABBITMQ CONFIGURATION ==========
      - RABBITMQ_URL=amqp://127.0.0.1:5672
      
      # Input exchanges from SLAM3R
      - SLAM3R_KEYFRAME_EXCHANGE=${SLAM3R_KEYFRAME_EXCHANGE:-slam3r_keyframe_exchange}
      
      # ========== TSDF VOLUME CONFIGURATION ==========
      # Adjust these based on your scene - current values for hallway scene
      # Updated to match actual point cloud bounds (points are at ~[20-27, 0-7, 20-28])
      - TSDF_VOLUME_MIN=15,-2,15
      - TSDF_VOLUME_MAX=32,10,32
      - TSDF_VOXEL_SIZE=0.05
      - TSDF_TRUNCATION_DISTANCE=0.10
      
      # ========== RERUN VISUALIZATION ==========
      - RERUN_VIEWER_ADDRESS=127.0.0.1:9876
      - RERUN_ENABLED=${RERUN_ENABLED:-true}
      
      # ========== METRICS CONFIGURATION ==========
      - METRICS_PORT=${MESH_SERVICE_METRICS_PORT:-9091}
      
      # ========== SHARED MEMORY CONFIGURATION ==========
      # Whether mesh_service should unlink shared memory after processing
      # Set to false if SLAM3R needs to confirm receipt
      - MESH_SERVICE_UNLINK_SHM=${MESH_SERVICE_UNLINK_SHM:-false}
      
      # ========== TSDF CONFIGURATION ==========
      # Core TSDF parameters (removed duplicates - see above)
      - TSDF_MAX_WEIGHT=${TSDF_MAX_WEIGHT:-100.0}             # Temporal averaging weight
      
      # Volume bounds optimized for actual point cloud data
      # Format: "x_min,y_min,z_min" and "x_max,y_max,z_max"
      # Note: These are now set above in lines 434-435 to match actual scene bounds
      
      # Performance tuning
      - TSDF_BLOCK_SIZE=${TSDF_BLOCK_SIZE:-8}                 # Voxel blocks for cache efficiency
      - TSDF_MAX_MESH_VERTICES=${TSDF_MAX_MESH_VERTICES:-10000000}  # 10M vertices max
      - TSDF_INTEGRATION_WEIGHT=${TSDF_INTEGRATION_WEIGHT:-1.0}     # Weight for new observations
      
      # Features
      - TSDF_COLOR_INTEGRATION=${TSDF_COLOR_INTEGRATION:-true}      # Enable color from RGB
      - TSDF_USE_SPACE_CARVING=${TSDF_USE_SPACE_CARVING:-false}     # Remove unseen voxels
      - TSDF_MIN_WEIGHT_THRESHOLD=${TSDF_MIN_WEIGHT_THRESHOLD:-1.0} # Min weight for mesh extraction
      - TSDF_GRADIENT_DELTA=${TSDF_GRADIENT_DELTA:-0.01}            # For normal estimation
      
      # ========== ALGORITHM SELECTION (NEW) ==========
      # Algorithm selection mode
      - MESH_ALGORITHM=${MESH_ALGORITHM:-OPEN3D_POISSON}              # AUTO, MARCHING_CUBES, OPEN3D_POISSON, NKSR
      
      # ========== OPEN3D POISSON CONFIGURATION ==========
      # Open3D Poisson reconstruction parameters
      - MESH_POISSON_OCTREE_DEPTH=${POISSON_OCTREE_DEPTH:-8}
      - MESH_POISSON_WIDTH=${POISSON_WIDTH:-0.0}
      - MESH_POISSON_SCALE=${POISSON_SCALE:-1.1}
      - MESH_POISSON_LINEAR_FIT=${POISSON_LINEAR_FIT:-false}
      - MESH_POISSON_THREADS=${POISSON_THREADS:-0}
      
      # Density filtering
      - MESH_POISSON_DENSITY_FILTER=${POISSON_DENSITY_FILTER:-true}
      - MESH_POISSON_DENSITY_PERCENTILE=${POISSON_DENSITY_PERCENTILE:-0.1}
      
      # SLAM3R-specific settings
      - MESH_POISSON_USE_CONFIDENCE=${POISSON_USE_CONFIDENCE:-true}
      - MESH_POISSON_CONFIDENCE_THRESHOLD=${POISSON_CONFIDENCE_THRESHOLD:-12.0}
      - MESH_POISSON_POINT_WEIGHT=${MESH_POISSON_POINT_WEIGHT:-4.0}
      - MESH_POISSON_SOLVER_ITERATIONS=${MESH_POISSON_SOLVER_ITERATIONS:-8}
      
      # ========== MEMORY CONFIGURATION ==========
      - MESH_MEMORY_POOL_SIZE=${MESH_MEMORY_POOL_SIZE:-1073741824}      # 1GB in bytes
      - MESH_MEMORY_BLOCK_SIZE=${MESH_MEMORY_BLOCK_SIZE:-67108864}      # 64MB in bytes
      - MESH_OCTREE_POOL_SIZE=${MESH_OCTREE_POOL_SIZE:-536870912}       # 512MB in bytes
      - MESH_SOLVER_POOL_SIZE=${MESH_SOLVER_POOL_SIZE:-268435456}       # 256MB in bytes
      - MESH_MAX_GPU_MEMORY=${MESH_MAX_GPU_MEMORY:-4294967296}          # 4GB limit
      
      # ========== ALGORITHM PARAMETERS ==========
      - MESH_NORMAL_K_NEIGHBORS=${MESH_NORMAL_K_NEIGHBORS:-30}
      - MESH_TRUNCATION_DISTANCE=${MESH_TRUNCATION_DISTANCE:-0.15}
      - MESH_MAX_VERTICES=${MESH_MAX_VERTICES:-5000000}
      - MESH_SIMPLIFICATION_RATIO=${MESH_SIMPLIFICATION_RATIO:-0.1}
      - MESH_MAX_TSDF_WEIGHT=${MESH_MAX_TSDF_WEIGHT:-100.0}
      - MESH_CONFIDENCE_THRESHOLD=${MESH_CONFIDENCE_THRESHOLD:-0.1}
      - MESH_INFLUENCE_RADIUS=${MESH_INFLUENCE_RADIUS:-0.1}
      - MESH_VOXEL_SIZE=${MESH_VOXEL_SIZE:-0.05}
      - MESH_ISO_VALUE=${MESH_ISO_VALUE:-0.0}
      
      # ========== SCENE CONFIGURATION ==========
      - MESH_MAX_SCENE_COORDINATE=${MESH_MAX_SCENE_COORDINATE:-1000.0}  # 1km max
      - MESH_OCTREE_SCENE_SIZE=${MESH_OCTREE_SCENE_SIZE:-10.0}         # 10m octree
      - MESH_OCTREE_MAX_DEPTH=${MESH_OCTREE_MAX_DEPTH:-8}
      - MESH_OCTREE_LEAF_SIZE=${MESH_OCTREE_LEAF_SIZE:-64}
      - MESH_OVERLAP_THRESHOLD=${MESH_OVERLAP_THRESHOLD:-0.9}           # 90% overlap
      
      # ========== PERFORMANCE THRESHOLDS ==========
      - MESH_CAMERA_VELOCITY_THRESHOLD=${MESH_CAMERA_VELOCITY_THRESHOLD:-0.1}    # m/s
      - MESH_VELOCITY_THRESHOLD_HIGH=${MESH_VELOCITY_THRESHOLD_HIGH:-2.0}        # m/s
      - MESH_VELOCITY_THRESHOLD_LOW=${MESH_VELOCITY_THRESHOLD_LOW:-0.5}          # m/s
      - MESH_TIME_DELTA_THRESHOLD=${MESH_TIME_DELTA_THRESHOLD:-0.001}            # seconds
      - MESH_VELOCITY_SMOOTH_FACTOR=${MESH_VELOCITY_SMOOTH_FACTOR:-0.8}
      - MESH_VELOCITY_CURRENT_FACTOR=${MESH_VELOCITY_CURRENT_FACTOR:-0.2}
      - MESH_SWITCH_STABILITY_FRAMES=${MESH_SWITCH_STABILITY_FRAMES:-5}
      - MESH_POINT_COUNT_THRESHOLD=${MESH_POINT_COUNT_THRESHOLD:-100000}
      - MESH_COMPLEXITY_THRESHOLD=${MESH_COMPLEXITY_THRESHOLD:-0.7}
      
      # ========== DEBUG CONFIGURATION ==========
      - MESH_FPS_LOG_INTERVAL=${MESH_FPS_LOG_INTERVAL:-30}              # Log FPS every N frames
      - MESH_DEBUG_SAVE_INTERVAL=${MESH_DEBUG_SAVE_INTERVAL:-10}        # Save debug every N frames
      - MESH_DEBUG_PRINT_LIMIT=${MESH_DEBUG_PRINT_LIMIT:-5}             # Print first N items
      - MESH_MAX_POINTS_TO_SCAN=${MESH_MAX_POINTS_TO_SCAN:-1000000}     # Max points for bounds
      - MESH_DEBUG_VOXEL_LIMIT=${MESH_DEBUG_VOXEL_LIMIT:-10}           # Debug voxel limit
      - MESH_DEBUG_POINT_LIMIT=${MESH_DEBUG_POINT_LIMIT:-10}           # Debug point limit
      - MESH_DEBUG_CONFIG=${MESH_DEBUG_CONFIG:-false}                   # Log config at startup
      - MESH_DEBUG_OUTPUT_DIR=${MESH_DEBUG_OUTPUT_DIR:-/debug_output}   # Debug output directory
      
      # Velocity thresholds for adaptive quality
      - VELOCITY_THRESHOLD_HIGH=${VELOCITY_THRESHOLD_HIGH:-0.5}      # High velocity threshold (m/s)
      - VELOCITY_THRESHOLD_LOW=${VELOCITY_THRESHOLD_LOW:-0.3}        # Low velocity threshold (m/s)
      
      # Point cloud complexity thresholds
      - POINT_COUNT_THRESHOLD=${POINT_COUNT_THRESHOLD:-100000}       # Threshold for algorithm switching
      - COMPLEXITY_THRESHOLD=${COMPLEXITY_THRESHOLD:-0.7}            # Scene complexity threshold
      
      # ========== GPU AND DISPLAY ==========
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_PATH=${CUDA_PATH}
      - LIBGL_ALWAYS_INDIRECT=${LIBGL_ALWAYS_INDIRECT}
      - DISPLAY=${DISPLAY}
      
      # ========== PERFORMANCE SETTINGS ==========
      - OMP_NUM_THREADS=4
      - CUDA_LAUNCH_BLOCKING=0
      
      # ========== LOGGING ==========
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    
    depends_on:
      - rabbitmq

  simulator:
    build: ./simulation  # or point to a Dockerfile that includes your simulation script
    profiles: ["simulator"]
    image: simulator:latest
    network_mode: host
    restart: "no"  # Don't restart when simulation completes
    environment:
      - PYTHONUNBUFFERED=1  # Ensures Python output is sent straight to the terminal
      - SERVER_WS_URL=ws://127.0.0.1:5001/ws/video  # WebSocket URL for H.264 streaming
      - SIMULATION_MODE=${SIMULATION_MODE:-video}  # Set to 'video' or 'segments'
    # NOTE: Can't use depends_on with network_mode: host

  website:
    image: website:latest
    build:
      context: ./website
      args:
        USERNAME: ${USERNAME}
        UID: ${UID}
        GID: ${GID}
    container_name: website
    volumes:
      - ${WORKSPACE}/website:/app
      - /app/node_modules
    environment:
      VITE_API_URL: "http://134.117.167.139/api"
      VITE_WS_HOST: "134.117.167.139"
      NODE_ENV: "development"
    depends_on:
      - rabbitmq
      - server

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - "9090:9090"
    extra_hosts:
    - "host.docker.internal:host-gateway"
    depends_on:
      - cadvisor
    networks:
      - default

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - default

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - default
    cpus: '0.2'

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    environment:
      COLLECTOR_OTLP_ENABLED: "true"       # Enable OTLP ingestion
      COLLECTOR_OTLP_HTTP_HOST_PORT: ":4318"
    ports:
      - "16686:16686"    # Jaeger UI
      - "6831/udp"       # Legacy agent port
      - "6832/udp"
      - "14268:14268"
      - "4318:4318"      # OTLP endpoint
    networks:
      - default

  nvidia-dcgm-exporter:
    # use NVIDIA's canonical registry & newest tag
    image: nvcr.io/nvidia/k8s/dcgm-exporter:4.2.3-4.1.1-ubuntu22.04
    container_name: nvidia-dcgm-exporter
    runtime: nvidia

    # full set of GPU‑profiling metrics needs SYS_ADMIN
    cap_add:
      - SYS_ADMIN

    environment:
      - NVIDIA_VISIBLE_DEVICES=all        # all GPUs
    ports:
      - "9400:9400"

    networks:
      - default

  storage:
    build:
      context: .
      dockerfile: ./storage/Dockerfile
    image: storage:latest
    container_name: worldsystem-storage
    network_mode: host
    environment:
      # ========== WebSocket Video Configuration ==========
      - VIDEO_STREAM_URL=ws://127.0.0.1:5001/ws/video/consume
      - VIDEO_STREAM_TYPE=websocket
      # ========== RabbitMQ Configuration ==========
      - RABBITMQ_URL=amqp://127.0.0.1:5672
      - FRAME_PROCESSOR_SKIP=1  # Record every frame
      
      # ========== Storage Configuration ==========
      - STORAGE_PATH=/app/recordings
      - VIDEO_CHUNK_DURATION_SECONDS=${VIDEO_CHUNK_DURATION_SECONDS:-60}  # 1 minute chunks by default
      - VIDEO_IDLE_TIMEOUT_SECONDS=${VIDEO_IDLE_TIMEOUT_SECONDS:-10.0}  # Save partial chunk after 10s of no frames
      - MIN_CHUNK_FRAMES=${MIN_CHUNK_FRAMES:-30}  # Minimum frames to save a partial chunk
      - USE_H264_CODEC=${USE_H264_CODEC:-false}  # Use H.264 codec instead of MJPEG
      
      # ========== System Configuration ==========
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - METRICS_PORT=8005
      - PYTHONUNBUFFERED=1
      
    volumes:
      - ${WORKSPACE}/storage:/app/storage:ro
      - ${WORKSPACE}/common:/app/common:ro
      - ${WORKSPACE}/recordings:/app/recordings
      - ${WORKSPACE}/data:/data  # Legacy compatibility
      
    depends_on:
      - rabbitmq
      
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://127.0.0.1:5001/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

networks:
  default:
    driver: bridge

volumes:
  grafana-data:
  rabbitmq-data:
