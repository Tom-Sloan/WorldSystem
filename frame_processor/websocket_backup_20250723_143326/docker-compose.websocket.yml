version: '3.8'

services:
  frame_processor_websocket:
    build:
      context: .
      dockerfile: frame_processor/Dockerfile.websocket
    container_name: worldsystem-frame_processor_websocket
    environment:
      - WS_HOST=server
      - WS_PORT=5001
      - RABBITMQ_URL=amqp://admin:admin@rabbitmq:5672/
      - PYTHONUNBUFFERED=1
      - FRAME_PROCESSOR_SKIP=1  # Process every frame
      - MODEL_NAME=sam2_tiny    # Start with tiny model for testing
      - TARGET_FPS=15
      - PROCESSING_RESOLUTION=720
      - LOG_LEVEL=INFO
      - METRICS_PORT=8003
      # Rerun connection
      - RERUN_HOST=host.docker.internal  # For Docker Desktop
      - RERUN_PORT=9876
    volumes:
      - ./frame_processor:/app/frame_processor:ro
      - ./common:/app/common:ro
      - ./enhanced_objects:/app/enhanced_objects
      - ./logs/frame_processor:/app/logs
      - frame_processor_models:/app/models
    networks:
      - worldsystem
    ports:
      - "8003:8003"  # Prometheus metrics
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  worldsystem:
    external: true
    name: worldsystem_default

volumes:
  frame_processor_models:
    external: true
    name: worldsystem_frame_processor_models